<!DOCTYPE html>
<html>
<head>
<title>kNN</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">
/* GitHub stylesheet for MarkdownPad (http://markdownpad.com) */
/* Author: Nicolas Hery - http://nicolashery.com */
/* Version: b13fe65ca28d2e568c6ed5d7f06581183df8f2ff */
/* Source: https://github.com/nicolahery/markdownpad-github */

/* RESET
=============================================================================*/

html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, img, ins, kbd, q, s, samp, small, strike, strong, sub, sup, tt, var, b, u, i, center, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td, article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary, time, mark, audio, video {
  margin: 0;
  padding: 0;
  border: 0;
}

/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

body>*:first-child {
  margin-top: 0 !important;
}

body>*:last-child {
  margin-bottom: 0 !important;
}

/* BLOCKS
=============================================================================*/

p, blockquote, ul, ol, dl, table, pre {
  margin: 15px 0;
}

/* HEADERS
=============================================================================*/

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
}

h1 tt, h1 code, h2 tt, h2 code, h3 tt, h3 code, h4 tt, h4 code, h5 tt, h5 code, h6 tt, h6 code {
  font-size: inherit;
}

h1 {
  font-size: 28px;
  color: #000;
}

h2 {
  font-size: 24px;
  border-bottom: 1px solid #ccc;
  color: #000;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777;
  font-size: 14px;
}

body>h2:first-child, body>h1:first-child, body>h1:first-child+h2, body>h3:first-child, body>h4:first-child, body>h5:first-child, body>h6:first-child {
  margin-top: 0;
  padding-top: 0;
}

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0;
}

h1+p, h2+p, h3+p, h4+p, h5+p, h6+p {
  margin-top: 10px;
}

/* LINKS
=============================================================================*/

a {
  color: #4183C4;
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

/* LISTS
=============================================================================*/

ul, ol {
  padding-left: 30px;
}

ul li > :first-child, 
ol li > :first-child, 
ul li ul:first-of-type, 
ol li ol:first-of-type, 
ul li ol:first-of-type, 
ol li ul:first-of-type {
  margin-top: 0px;
}

ul ul, ul ol, ol ol, ol ul {
  margin-bottom: 0;
}

dl {
  padding: 0;
}

dl dt {
  font-size: 14px;
  font-weight: bold;
  font-style: italic;
  padding: 0;
  margin: 15px 0 5px;
}

dl dt:first-child {
  padding: 0;
}

dl dt>:first-child {
  margin-top: 0px;
}

dl dt>:last-child {
  margin-bottom: 0px;
}

dl dd {
  margin: 0 0 15px;
  padding: 0 15px;
}

dl dd>:first-child {
  margin-top: 0px;
}

dl dd>:last-child {
  margin-bottom: 0px;
}

/* CODE
=============================================================================*/

pre, code, tt {
  font-size: 12px;
  font-family: Consolas, "Liberation Mono", Courier, monospace;
}

code, tt {
  margin: 0 0px;
  padding: 0px 0px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px;
}

pre>code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent;
}

pre {
  background-color: #f8f8f8;
  border: 1px solid #ccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px;
}

pre code, pre tt {
  background-color: transparent;
  border: none;
}

kbd {
    -moz-border-bottom-colors: none;
    -moz-border-left-colors: none;
    -moz-border-right-colors: none;
    -moz-border-top-colors: none;
    background-color: #DDDDDD;
    background-image: linear-gradient(#F1F1F1, #DDDDDD);
    background-repeat: repeat-x;
    border-color: #DDDDDD #CCCCCC #CCCCCC #DDDDDD;
    border-image: none;
    border-radius: 2px 2px 2px 2px;
    border-style: solid;
    border-width: 1px;
    font-family: "Helvetica Neue",Helvetica,Arial,sans-serif;
    line-height: 10px;
    padding: 1px 4px;
}

/* QUOTES
=============================================================================*/

blockquote {
  border-left: 4px solid #DDD;
  padding: 0 15px;
  color: #777;
}

blockquote>:first-child {
  margin-top: 0px;
}

blockquote>:last-child {
  margin-bottom: 0px;
}

/* HORIZONTAL RULES
=============================================================================*/

hr {
  clear: both;
  margin: 15px 0;
  height: 0px;
  overflow: hidden;
  border: none;
  background: transparent;
  border-bottom: 4px solid #ddd;
  padding: 0;
}

/* TABLES
=============================================================================*/

table th {
  font-weight: bold;
}

table th, table td {
  border: 1px solid #ccc;
  padding: 6px 13px;
}

table tr {
  border-top: 1px solid #ccc;
  background-color: #fff;
}

table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

/* IMAGES
=============================================================================*/

img {
  max-width: 100%
}
</style>
</head>
<body>
<h1>k-临近算法</h1>
<h2></h2>
<h4>1 概述</h4>
<p>　　</p>
<p>简单的说，K-近邻值法采用测量不同特征值之间的距离方法进行分类
　</p>
<blockquote>
<p>　　优点：精度高，对异常值不敏感，无数据输入假定。</br>
　　缺点：计算复杂度高、空间复杂度高</br>
　　适用范围：数值型和标称型</br></p>
</blockquote>
<p>k-近邻值法的一般流程：</p>
<blockquote>
<p>　　（１）收集数据：任何方法</br>
　　（２）准备数据：计算机里所需要的值，最好是结构化数据</br>
　　（３）分析数据：任何方法</br>
　　（４）训练算法：不适用</br>
　　（５）测试算法：计算错误率</br>
　　（６）使用算法：输入样本数据和结构化的输出结果，运行K-临近值判定输入数据的分类，最后对分类执行后续处理。</p>
</blockquote>
<h4>2　k-近邻算法概述</h4>
<h4>2.1  使用Python导入数据</h4>
<p></br>
建立kNN.py文件，导入模块：科学计算包NumPy和运算符模块operator，创建一个DataSet</br>
导入matplotlib包是为了之后的分析</p>
<p>　　</p>
<pre><code>from numpy import *
import operator
import matplotlib
import matplotlib.pyplot as plt
import os


def creatDataSet():
    group = array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])
    labels = ['A','A','B','B']
    return group, labels
</code></pre>

<p>group里每组数据包含了两个属性或者特征值，向量label则包含了每个数据的标签信息</p>
<h4>2.2 实施kNN算法</h4>
<p></br>
主要是使用k-近邻值算法将每组数据划分到某个类中</br></p>
<pre><code>def classify0(inX, dataSet, labels, k):
    #四个输入参数：用于分类的输入向量inX，输入的训练样本集dataSet，标签向量label，选择最近邻居的数目k
    dataSetSize = dataSet.shape[0]
    diffMat = tile(inX, (dataSetSize,1)) - dataSet
    #tile函数用inX减去dataSet中的数，获得向量差
    sqDiffMat = diffMat**2 
    sqDistances = sqDiffMat.sum(axis=1)
    distances = sqDistances**0.5 #使用欧式距离公式
    sortedDistIndicies = distances.argsort()
    classCount={}
    for i in range(k):
        voteIlabel = labels[sortedDistIndicies[i]]
        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1
    sortedClassCount = sorted(classCount.iteritems(),key=operator.itemgetter(1),reverse=True)
    #sorted函数排序，获得从小到大排序结果
    return sortedClassCount[0][0] #获得最小值
</code></pre>

<h4>3 示例：使用k-近邻算法</h4>
<h4>3.1在约会网站上使用k-近邻算法：</h4>
<blockquote>
<p>　　（１）收集数据：提供文本文件</br>
　　（２）准备数据：使用Python解析文本文件</br>
　　（３）分析数据：使用Maiplotlib画二位扩散图</br>
　　（４）训练算法：不适用</br>
　　（５）测试算法：使用某用户提供的部分数据</br>
　　（６）使用算法：产生简单的命令行程序，可以输入特征数据以判断是否喜欢。</p>
</blockquote>
<p>将文本记录转换为NumPy的解析程序：</p>
<pre><code>def file2matrix(filename):
    fr = open(filename)
    arrayOLines = fr.readlines() #返回一个包含行的列表
    numberOfLines = len(arrayOLines) #得到文件行数
    returnMat = zeros((numberOfLines,3 )) #创建返回的NumPy矩阵，初始为0
    classLabelVector = []
    index = 0
    for line in arrayOLines:
        line =  line.strip() #截取所有回车字符
        listFromLine = line.split('\t')  #使用\t分割行数据为元素列表
        returnMat[index,:] = listFromLine[0:3] #截取每行前三个放入矩阵
        classLabelVector.append(int(listFromLine[-1]))
        index +=1
    return returnMat, classLabelVector

datingDataMat, datingLabels = file2matrix('E:\Python_code\machinelearninginaction\Ch02\datingTestSet2.txt')
</code></pre>

<h4>3.2 分析数据：使用Matplotlib 画图</h4>
<pre><code>#print datingDataMat

# fig = plt.figure()
# ax = fig.add_subplot(111)
# ax.scatter(datingDataMat[:,1], datingDataMat[:,2],15.0*array(datingLabels),15.0*array(datingLabels))
# 
# plt.show()
</code></pre>

<p>获得了散点图，绘制了色彩不等、尺寸不同的点</p>
<h4>3.3 准备数据：归一化数值</h4>
<p>　　各个样本的量级不同，使用欧式距离公式使得量级大的特征影响远远大于其他，为了消除这个影响，应当进行归一化处理</p>
<p>主要公式为：</br>
　　newValue = (oldValue-min)/(max-min)</p>
<pre><code>def autoNorm(dataSet):
    minVals = dataSet.min(0)
    maxVals = dataSet.max(0)
    ranges = maxVals - minVals
    normDataSet = zeros(shape(dataSet))
    m = dataSet.shape[0]
    normDataSet = dataSet - tile(minVals, (m,1))
    normDataSet = normDataSet/tile(ranges, (m,1))
    return normDataSet, ranges, minVals 

normMat, ranges, minVals = autoNorm(datingDataMat)    
</code></pre>

<h4>3.4 测试算法：作为完整程序验证分类器</h4>
<p>　　本节来测试分类器的效果。通常提供已有数据的90%来训练样本来训练分类器，使用其余的10%来测试分类器，检测分类器的正确率。注意10%的数据应该是随机选择的</p>
<pre><code>def datingClassTest():
    hoRatio = 0.10      #使用10%的数据
    datingDataMat,datingLabels = file2matrix('E:\Python_code\machinelearninginaction\Ch02\datingTestSet2.txt')       
    normMat, ranges, minVals = autoNorm(datingDataMat) #归一化
    m = normMat.shape[0]
    numTestVecs = int(m*hoRatio) #计算测试向量数量
    errorCount = 0.0
    for i in range(numTestVecs): #使用分类器进行测试
        classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3)
        print &quot;the classifier came back with: %d, the real answer is: %d&quot; % (classifierResult, datingLabels[i])
        if (classifierResult != datingLabels[i]): errorCount += 1.0
        #与label对比，计算错误率
    print &quot;the total error rate is: %f&quot; % (errorCount/float(numTestVecs))

#datingClassTest()        
</code></pre>

<h4>4 手写识别系统   </br></h4>
<p>　　本节构造使用k-近邻算法的手写识别系统。此处只能识别数字0-9，为了便于理解将图像转换为文本格式。</p>
<blockquote>
<p>　　（１）收集数据：提供文本文件</br>
　　（２）准备数据：编写函数img2vector，图像格式转换为向量格式</br>
　　（３）分析数据：在Python命令符中检查数据</br>
　　（４）训练算法：不适用</br>
　　（５）测试算法：提供部分数据集为测试样本</br>
　　（６）使用算法：无。
　　</p>
</blockquote>
<h4>4.1 准备数据：将图像转换为测试向量</h4>
<p>　把一个32*32的二进制图像矩阵转化为1*1024的向量，然后循环读出文件的前32行，并存储每行的前32个字符值，最后返回数组。</p>
<pre><code>def img2vector(filename):
    returnVect = zeros((1,1024))
    fr = open(filename)
    for i in range(32):
        lineStr = fr.readline()
        for j in range(32):
            returnVect[0,32*i+j] = int(lineStr[j])
    return returnVect

testVector = img2vector(r'E:\Python_code\machinelearninginaction\Ch02\0_13.txt')

#print testVector[0,0:31]
</code></pre>

<h4>4.2 测试算法：用k-近邻算法识别手写数字</h4>
<pre><code>def handwritingClassTest():
    hwLabels = []
    trainingFileList = os.listdir(r'E:\Python_code\machinelearninginaction\Ch02\trainingDigits')  
    #获取目录内容
    m = len(trainingFileList)
    trainingMat = zeros((m,1024))
    for i in range(m):
        fileNameStr = trainingFileList[i]
        fileStr = fileNameStr.split('.')[0]     
        classNumStr = int(fileStr.split('_')[0]) #通过文件名解析数字
        hwLabels.append(classNumStr) #存入标签
        trainingMat[i,:] = img2vector(r'E:\Python_code\machinelearninginaction\Ch02\trainingDigits\%s' % fileNameStr)
    testFileList = os.listdir(r'E:\Python_code\machinelearninginaction\Ch02\testDigits')        #遍历文件名
    errorCount = 0.0
    mTest = len(testFileList)
    for i in range(mTest):
        fileNameStr = testFileList[i]
        print fileNameStr
        fileStr = fileNameStr.split('.')[0]     
        classNumStr = int(fileStr.split('_')[0])
        vectorUnderTest = img2vector(r'E:\Python_code\machinelearninginaction\Ch02\testDigits\%s' % fileNameStr)
        classifierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3)
        print &quot;the classifier came back with: %d, the real answer is: %d&quot; % (classifierResult, classNumStr)
        if (classifierResult != classNumStr): errorCount += 1.0
    print &quot;\nthe total number of errors is: %d&quot; % errorCount
    print &quot;\nthe total error rate is: %f&quot; % (errorCount/float(mTest))



handwritingClassTest()    
</code></pre>

<h4>5 本章小结</h4>
<p>　　k-近邻算法是分类数据最简单最有效的方法，本章通过两个例子讲述了如何使用k-近邻算法</p>

</body>
</html>
<!-- This document was created with MarkdownPad, the Markdown editor for Windows (http://markdownpad.com) -->
